{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import os as os\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.misc\n",
    "import array\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import io\n",
    "import random\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import operator\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, mean_absolute_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB(X_train, y_train):\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    clf = BernoulliNB(alpha=1.0e-10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataStandarization(outputDirectory):\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    # Train\n",
    "    trainData = pd.read_csv(outputDirectory+\"featuresCsvTrainWithLabels.csv\")\n",
    "    X_train = trainData.iloc[:,1:-1] # split train and labels\n",
    "    y_train = trainData.iloc[:,-1]\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    dataFilesNames = pd.DataFrame(trainData['filename'])\n",
    "    X_trainDF = pd.DataFrame(X_train)\n",
    "    trainDataStandarizedWithNames = dataFilesNames.join(X_trainDF) # put names and data together\n",
    "    trainLabels = trainData.iloc[:,[0,-1]] # Get filename and labels\n",
    "    trainDataStandarizedWithLabels = trainDataStandarizedWithNames.merge(trainLabels, on='filename')\n",
    "    # Test\n",
    "    testData = pd.read_csv(outputDirectory+\"featuresCsvTestWithLabels.csv\")\n",
    "    X_test = testData.iloc[:,1:-1] # split train and labels\n",
    "    y_test = testData.iloc[:,-1]\n",
    "    X_test = scaler.transform(X_test)\n",
    "    dataFilesNames = pd.DataFrame(testData['filename'])\n",
    "    X_testDF = pd.DataFrame(X_test)\n",
    "    testDataStandarizedWithNames = dataFilesNames.join(X_testDF)\n",
    "    testLabels = testData.iloc[:,[0,-1]] # Get filename and labels\n",
    "    testDataStandarizedWithLabels = testDataStandarizedWithNames.merge(testLabels, on='filename')\n",
    "    return trainDataStandarizedWithLabels,testDataStandarizedWithLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eagle/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/eagle/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/eagle/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "outputPath='Data/'\n",
    "trainDataReducedWithLabels,testDataReducedWithLabels = dataStandarization(outputPath)\n",
    "# Split data\n",
    "X_train = trainDataReducedWithLabels.iloc[:,1:-1] \n",
    "y_train = trainDataReducedWithLabels.iloc[:,-1]\n",
    "X_test = testDataReducedWithLabels.iloc[:,1:-1] \n",
    "y_test = testDataReducedWithLabels.iloc[:,-1]\n",
    "# Trainning\n",
    "clfNB = trainNB(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = clfNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:  [[24  1]\n",
      " [ 2 26]]\n",
      "Accuracy Score NB:  0.9433962264150944\n",
      "(0.944148793205397, 0.9433962264150944, 0.9434365856119463, None)\n",
      "Mean absolute error:  0.05660377358490566\n"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix: \", cnf_matrix)\n",
    "NBAccuracy = accuracy_score(y_test, y_pred)\n",
    "NBMae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Accuracy Score NB: \", NBAccuracy)\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='weighted'))\n",
    "print(\"Mean absolute error: \", NBMae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
