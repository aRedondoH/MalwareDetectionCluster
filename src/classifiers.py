from csv import writer
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing
from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2
from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, mean_absolute_error, make_scorer
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn import metrics
import pandas as pd
import numpy as np
from sklearn.naive_bayes import BernoulliNB,MultinomialNB, GaussianNB
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from xgboost import XGBClassifier

def safe_div(x,y):
    if y == 0:
        return 0
    return x / y

def createNbClassifier():
    # clfNB = BernoulliNB(alpha=1.0e-10) # Binary features
    clfNB = GaussianNB(var_smoothing=1) # Continous features
    return clfNB
def createRfClassifier():
    clfRf = RandomForestClassifier(n_estimators=150,
                                  max_features=0.6,
                                  max_depth=3,
                                  min_samples_split=30,
                                  min_samples_leaf=1)
    return clfRf
def createXgClassifier():
    clfXg = XGBClassifier(
        learning_rate =0.3,
        n_estimators=600,
        max_depth=10,
        min_child_weight=1,
        gamma=0.3,
        subsample=0.5,
        colsample_bytree=0.8,
        objective= 'binary:logistic',
        nthread=6,
        scale_pos_weight=1,
        seed=27)
    return clfXg

def createVotingClassifier(clf1,clf2,clf3):
    clfVoting = VotingClassifier(estimators=[('clf1', clf1), ('clf2', clf2), ('clf3', clf3)],voting='hard', weights=[1,2,3])
    return clfVoting

def xposterior(X, obj):
    # return(np.exp(obj._joint_log_likelihood(X)))
    # return(obj._joint_log_likelihood(X))
    return(obj.predict_proba(X))

def utilitySenLabels(Xp, obj, ut):
    aux = np.dot(ut, xposterior(Xp,obj).transpose())
    print("Xp: ", Xp)
    print("Ut: ", ut)
    print("Posterior: ")
    print(xposterior(Xp,obj))
    print("Posterior traspose: ")
    print(xposterior(Xp,obj).transpose())
    print("Ut x posterior: ", aux)
    print("Argmax: ", np.argmax(aux, axis=0))
    return(np.argmax(aux, axis=0))

def dataStandarization(X_data):
    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)
    X_data.fillna(0,inplace=True)
    X_data = scaler.fit_transform(X_data)
    return X_data

def classifyCrossValidated(X_data,y_data,i):

    clfNB = createNbClassifier()
    clfRf = createRfClassifier()
    clfXg = createXgClassifier()

    scoresNB = cross_val_score(clfNB, X_data, y_data, cv=5)
    scoresNBmacro = cross_val_score(clfNB, X_data, y_data, cv=5, scoring='f1_macro')
    scoresNBweighted = cross_val_score(clfNB, X_data, y_data, cv=5, scoring='f1_weighted')
    
    scoresRf = cross_val_score(clfRf, X_data, y_data, cv=5)
    scoresRfmacro = cross_val_score(clfRf, X_data, y_data, cv=5, scoring='f1_macro')
    scoresRfweighted = cross_val_score(clfRf, X_data, y_data, cv=5, scoring='f1_weighted')

    scoresXg = cross_val_score(clfXg, X_data, y_data, cv=5)
    scoresXgmacro = cross_val_score(clfXg, X_data, y_data, cv=5, scoring='f1_macro')
    scoresXgweighted = cross_val_score(clfXg, X_data, y_data, cv=5, scoring='f1_weighted')
    
    # Write results into csv
    results = [i, scoresNB.mean(),scoresNBmacro.mean(),scoresNBweighted.mean(),scoresNB.std() * 2, scoresRf.mean(),scoresRfmacro.mean(),scoresRfweighted.mean(),scoresRf.std() * 2,scoresXg.mean(),scoresXgmacro.mean(),scoresXgweighted.mean(),scoresXg.std() * 2]
    print(results)

    return results

def classifyCrossCombClassifiers(X_data,y_data,i):
    clfNB = createNbClassifier()
    clfRf = createRfClassifier()
    clfXg = createXgClassifier()
    clfVoting = createVotingClassifier(clfNB,clfRf,clfXg)

    scoresNB = cross_val_score(clfNB, X_data, y_data, cv=5)
    scoresRf = cross_val_score(clfRf, X_data, y_data, cv=5)
    scoresXg = cross_val_score(clfXg, X_data, y_data, cv=5)
    scoresCombined = cross_val_score(clfVoting, X_data, y_data, cv=5)
    

    # Write results into csv
    results = [i, scoresNB.mean(),scoresNB.std() * 2, scoresRf.mean(),scoresRf.std() * 2,scoresXg.mean(),scoresXg.std() * 2, scoresCombined.mean(), scoresCombined.std()*2]

    return results

def classifyCombClassifiers(X_data,y_data,i):
    clfNB = createNbClassifier()
    clfRf = createRfClassifier()
    clfXg = createXgClassifier()
    clfVoting = createVotingClassifier(clfNB,clfRf,clfXg)

    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=42)

    # NB
    y_pred = clfNB.fit(X_train,y_train).predict(X_test)
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    NBAccuracy = accuracy_score(y_test, y_pred)
    NBFpRate = safe_div( int(fp), int(tp)+int(fp) )
    NBFnRate = safe_div( int(fn), int(tn)+int(fn) )
    print("NB Accuracy:", NBAccuracy," FP:", NBFpRate, " FN:", NBFnRate)

    # RF
    y_pred = clfRf.fit(X_train,y_train).predict(X_test)
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    RFAccuracy = accuracy_score(y_test, y_pred)
    RFFpRate = safe_div( int(fp), int(tp)+int(fp) )
    RFFnRate = safe_div( int(fn), int(tn)+int(fn) )
    print("RF Accuracy:", RFAccuracy," FP:", RFFpRate, " FN:", RFFnRate)

    # XG
    y_pred = clfXg.fit(X_train,y_train).predict(X_test)
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    XGAccuracy = accuracy_score(y_test, y_pred)
    XGFpRate = safe_div( int(fp), int(tp)+int(fp) )
    XGFnRate = safe_div( int(fn), int(tn)+int(fn) )
    print("XG Accuracy:", XGAccuracy," FP:", XGFpRate, " FN:", XGFnRate)

    # VT
    y_pred = clfVoting.fit(X_train,y_train).predict(X_test)
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    VotAccuracy = accuracy_score(y_test, y_pred)
    VotFP = safe_div( int(fp), int(tp)+int(fp) )
    VotFN = safe_div( int(fn), int(tn)+int(fn) )
    print("Vot accuracy:", VotAccuracy, " FP:", VotFP, " FN:", VotFN)
    
    # Write results into csv
    # results = [i, NBAccuracy,NBFpRate,NBFnRate,RFAccuracy,RFFpRate,RFFnRate,XGAccuracy,XGFpRate,XGFnRate,VotAccuracy,VotFP,VotFN]
    results = [i, NBAccuracy,NBFpRate,NBFnRate,NBSenAccuracy,NBSenFpRate,NBSenFnRate,RFAccuracy,RFFpRate,RFFnRate,XGAccuracy,XGFpRate,XGFnRate,VotAccuracy,VotFP,VotFN]
    
    return results

def classifyCombClassifiersSen(X_data,y_data,i):
    clfNB = createNbClassifier()
    clfRf = createRfClassifier()
    clfXg = createXgClassifier()

    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=42)

    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))
    # print("X_train before: ", X_train)
    X_train = min_max_scaler.fit_transform(X_train)
    # print("X_train after: ", X_train)
    
    # Dat standarization (Test)
    X_test = min_max_scaler.transform(X_test)

    ut1_1=1
    ut1_2=0.1
    ut2_1=0
    ut2_2=1
    ut = np.array([[ut1_1,ut1_2],[ut2_1,ut2_2]])

    # NB sensitive
    clfNbTrained = clfNB.fit(X_train,y_train)
    y_pred = utilitySenLabels(X_test,clfNbTrained,ut)
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    NBSenAccuracy = accuracy_score(y_test, y_pred)
    NBeu = (tp*ut1_1)+(fn*ut2_1)+(fp*ut1_2)+(tn*ut2_2)
    # maxEu = max(tp*ut1_1,fn*ut2_1,fp*ut1_2,tn*ut2_2)
    NBSenFpRate = safe_div( int(fp), int(fp)+int(tn) )
    NBSenFnRate = safe_div( int(fn), int(fn)+int(tp) )
    print("NBSen AC:", NBSenAccuracy," EU: ",NBeu," FP:", NBSenFpRate, " FN:", NBSenFnRate)

    # RF sensitive
    clfRfTrained = clfRf.fit(X_train,y_train)
    y_pred = utilitySenLabels(X_test,clfRfTrained,ut)
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    RFSenAccuracy = accuracy_score(y_test, y_pred)
    RFeu = (tp*ut1_1)+(fn*ut2_1)+(fp*ut1_2)+(tn*ut2_2)
    # euR = eu/(tp+fn+fp+tn)
    RFSenFpRate = safe_div(int(fp), int(fp)+int(tn) )
    RFSenFnRate = safe_div( int(fn), int(fn)+int(tp) )
    print("RFSen AC:", RFSenAccuracy," EU: ",RFeu," FP:", RFSenFpRate, " FN:", RFSenFnRate)

    # XG sensitive
    clfXgTrained = clfXg.fit(X_train,y_train)
    y_pred = utilitySenLabels(X_test,clfXgTrained,ut)
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    XGSenAccuracy = accuracy_score(y_test, y_pred)
    XGeu = (tp*ut1_1)+(fn*ut2_1)+(fp*ut1_2)+(tn*ut2_2)
    # euR = eu/(tp+fn+fp+tn)
    XGSenFpRate = safe_div( int(fp), int(fp)+int(tn) )
    XGSenFnRate = safe_div( int(fn), int(fn)+int(tp) )
    print("XGSen AC:", XGSenAccuracy," EU: ",XGeu," FP:", XGSenFpRate, " FN:", XGSenFnRate)
    
    # Write results into csv
    results = [i, ut1_1,ut1_2,ut2_1,ut2_2,NBSenAccuracy,NBeu,NBSenFpRate,NBSenFnRate,RFSenAccuracy,RFeu,RFSenFpRate,RFSenFnRate,XGSenAccuracy,XGeu,XGSenFpRate,XGSenFnRate]
    return results
    

def classifyCrossFeatureSelection(X_data,y_data,numberOfFeatures):
    clfNB = createNbClassifier()
    clfRf = createRfClassifier()
    clfXg = createXgClassifier()

    scoresNB = cross_val_score(clfNB, X_data, y_data, cv=5)
    scoresNBmacro = cross_val_score(clfNB, X_data, y_data, cv=5, scoring='f1_macro')
    scoresNBweighted = cross_val_score(clfNB, X_data, y_data, cv=5, scoring='f1_weighted')
    
    scoresRf = cross_val_score(clfRf, X_data, y_data, cv=5)
    scoresRfmacro = cross_val_score(clfRf, X_data, y_data, cv=5, scoring='f1_macro')
    scoresRfweighted = cross_val_score(clfRf, X_data, y_data, cv=5, scoring='f1_weighted')

    scoresXg = cross_val_score(clfXg, X_data, y_data, cv=5)
    scoresXgmacro = cross_val_score(clfXg, X_data, y_data, cv=5, scoring='f1_macro')
    scoresXgweighted = cross_val_score(clfXg, X_data, y_data, cv=5, scoring='f1_weighted')
    
    # Write results into csv
    results = [numberOfFeatures, scoresNB.mean(),scoresNBmacro.mean(),scoresNBweighted.mean(),scoresNB.std() * 2, scoresRf.mean(),scoresRfmacro.mean(),scoresRfweighted.mean(),scoresRf.std() * 2,scoresXg.mean(),scoresXgmacro.mean(),scoresXgweighted.mean(),scoresXg.std() * 2]
    print(results)

    return results
    


def checkClassificationAlgorithms(trainDataReducedWithLabels,testDataReducedWithLabels, outputDirectory,i, csvFile):
    # Split data
    X_train = trainDataReducedWithLabels.iloc[:,1:-1] 
    y_train = trainDataReducedWithLabels.iloc[:,-1]
    X_test = testDataReducedWithLabels.iloc[:,1:-1] 
    y_test = testDataReducedWithLabels.iloc[:,-1]
    
    # 8.1 NB
    # Trainning
    clfNB = trainNB(X_train, y_train)
    # Predict
    y_pred = clfNB.predict(X_test)
    # Check confusion matrix, accuracy and recall
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    #tp,fn,fp,tn = cnf_matrix.ravel()
    NBAccuracy = accuracy_score(y_test, y_pred)
    NBMae = mean_absolute_error(y_test, y_pred)
    
    NBRecall = safe_div( int(tp), int(tp)+int(fn) )
    NBFpRate = safe_div( int(fp), int(tp)+int(fp) )
    NBFnRate = safe_div( int(fn), int(tn)+int(fn) )
    
    #print(precision_recall_fscore_support(y_test, y_pred, average='weighted'))
    print("NB Accuracy:", NBAccuracy," Recall:", NBRecall," FP:", NBFpRate, " FN:", NBFnRate," Mae:", NBMae)
    
    # 8.2 RF
    # Trainning
    clfRF = trainRF(X_train,y_train)
    # Predict
    y_pred = clfRF.predict(X_test)
    # Check confusion matrix, accuracy and recall 
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    RFAccuracy = accuracy_score(y_test, y_pred)
    RFMae = mean_absolute_error(y_test, y_pred)
    RFRecall = safe_div( int(tp), int(tp)+int(fn) )
    RFFpRate = safe_div( int(fp), int(tp)+int(fp) )
    RFFnRate = safe_div( int(fn), int(tn)+int(fn) )
    
    #print(precision_recall_fscore_support(y_test, y_pred, average='weighted'))
    print("RF Accuracy:", RFAccuracy," Recall:", RFRecall," FP:", RFFpRate, " FN:", RFFnRate," Mae:", RFMae)
    
    # 8.3 XGBoost
    clfXGBoost = trainXGBoost(X_train,y_train)
    # Predict
    y_pred = clfXGBoost.predict(X_test)
    # Check confusion matrix, accuracy and recall
    tp,fn,fp,tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()
    XGAccuracy = accuracy_score(y_test, y_pred)
    XGMae = mean_absolute_error(y_test, y_pred)
    XGRecall = safe_div( int(tp), int(tp)+int(fn) )
    XGFpRate = safe_div( int(fp), int(tp)+int(fp) )
    XGFnRate = safe_div( int(fn), int(tn)+int(fn) )
    
    #print(precision_recall_fscore_support(y_test, y_pred, average='weighted'))
    print("XG Accuracy:", XGAccuracy," Recall:", XGRecall," FP:", XGFpRate, " FN:", XGFnRate," Mae:", XGMae)
    
    # Write results into csv
    results = [i, NBAccuracy, NBRecall, NBFpRate, NBFnRate, NBMae, RFAccuracy, RFRecall, RFFpRate, RFFnRate, RFMae, XGAccuracy, XGRecall, XGFpRate, XGFnRate, XGMae]
    with open(csvFile, 'a') as f:
        fw = writer(f)
        fw.writerow(results)
